{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning_with_Pytorch-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPy8LZVfnY0ORc8luWDzG4W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishalrk1/pytorch/blob/main/DeepLearning_with_Pytorch_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Telling Dirds from airplanes"
      ],
      "metadata": {
        "id": "BYaUC69XKO-2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9k9Ibj8wJ6Lz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = 'CIFAR10/'\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2470, 0.2435, 0.2616))\n",
        "])\n",
        "\n",
        "train_data = datasets.CIFAR10(data_path, train=True, download=True, transform=transform)\n",
        "valid_data = datasets.CIFAR10(data_path, train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDdmvzy2KNMI",
        "outputId": "bdbcc6e2-ca89-4483-b787-03586bbc517f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgk5K3jXKqx8",
        "outputId": "911c2b16-1a60-4785-8815-a14cdda334aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes\n",
        "class_len = len(class_names)"
      ],
      "metadata": {
        "id": "8NcO-jV2MNgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[99]"
      ],
      "metadata": {
        "id": "LnZz3L0DLkY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = image.permute((1, 2, 0))\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "Mlu_1LOxMX21",
        "outputId": "44b3eeea-dbcb-44b0-f340-8f94c5cf4fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imgs = torch.stack([img for img, _ in train_data], dim=3)\n",
        "imgs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E053pMApMk16",
        "outputId": "52720e8e-e6aa-4f4a-e86d-86c4a1f4be20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 32, 50000])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imgs.view(3, -1).mean(dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lywUxxXrQFpq",
        "outputId": "8eb9ff8d-d200-41fb-8ef7-c7ffaff42647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4914, 0.4822, 0.4465])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imgs.view(3, -1).std(dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCoEcSJVQSyD",
        "outputId": "d9a82494-047a-45fc-922c-38a8eeb9d683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2470, 0.2435, 0.2616])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fzb2LOhQ74j",
        "outputId": "5e83acc6-1dbc-4d10-c496-2885dea8662d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['airplane',\n",
              " 'automobile',\n",
              " 'bird',\n",
              " 'cat',\n",
              " 'deer',\n",
              " 'dog',\n",
              " 'frog',\n",
              " 'horse',\n",
              " 'ship',\n",
              " 'truck']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {0: 0, 2: 1}\n",
        "class_names = ['airplane', 'bird']\n",
        "\n",
        "train_dataset = [(img, label_map[label]) for img, label in train_data if label in [0, 2]]\n",
        "\n",
        "valid_dataset = [(img, label_map[label]) for img, label in valid_data if label in [0, 2]]"
      ],
      "metadata": {
        "id": "_L5_8GN4R46d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42vZAwHpSbJq",
        "outputId": "971038ac-8a04-492e-a364-9c72fd2d972c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "32*32*3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9PvRNpwSkpJ",
        "outputId": "89f5fa30-239d-4143-c970-f9d1aee94587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3072"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining model\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(3072, 512),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(512, 2),\n",
        "    nn.LogSoftmax(dim= 1),\n",
        ")"
      ],
      "metadata": {
        "id": "3bVSvAwVSohG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "OTPTmkq-Twn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size = 32, shuffle=True)\n",
        "\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size = 32, shuffle=True)"
      ],
      "metadata": {
        "id": "e8upGQabUisX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for img, labels in train_dataloader:\n",
        "    batch_size = img.shape[0]\n",
        "    pred = model(img.view(batch_size, -1))\n",
        "    loss = criterion(pred, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eo_bo9abWxIb",
        "outputId": "47855817-2d38-4cf2-c600-25b87865f556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 0.248297\n",
            "Epoch: 1, Loss: 0.507545\n",
            "Epoch: 2, Loss: 0.470019\n",
            "Epoch: 3, Loss: 0.344460\n",
            "Epoch: 4, Loss: 0.473282\n",
            "Epoch: 5, Loss: 0.406540\n",
            "Epoch: 6, Loss: 0.361652\n",
            "Epoch: 7, Loss: 0.516309\n",
            "Epoch: 8, Loss: 0.198261\n",
            "Epoch: 9, Loss: 0.700940\n",
            "Epoch: 10, Loss: 0.268313\n",
            "Epoch: 11, Loss: 0.521171\n",
            "Epoch: 12, Loss: 0.154453\n",
            "Epoch: 13, Loss: 0.145037\n",
            "Epoch: 14, Loss: 0.302983\n",
            "Epoch: 15, Loss: 0.426984\n",
            "Epoch: 16, Loss: 0.536536\n",
            "Epoch: 17, Loss: 0.336187\n",
            "Epoch: 18, Loss: 0.389803\n",
            "Epoch: 19, Loss: 0.497461\n",
            "Epoch: 20, Loss: 0.433757\n",
            "Epoch: 21, Loss: 0.331496\n",
            "Epoch: 22, Loss: 0.276541\n",
            "Epoch: 23, Loss: 0.221667\n",
            "Epoch: 24, Loss: 0.431252\n",
            "Epoch: 25, Loss: 0.516633\n",
            "Epoch: 26, Loss: 0.319256\n",
            "Epoch: 27, Loss: 0.513841\n",
            "Epoch: 28, Loss: 0.392866\n",
            "Epoch: 29, Loss: 0.392488\n",
            "Epoch: 30, Loss: 0.642057\n",
            "Epoch: 31, Loss: 0.397947\n",
            "Epoch: 32, Loss: 0.264731\n",
            "Epoch: 33, Loss: 0.336315\n",
            "Epoch: 34, Loss: 0.573208\n",
            "Epoch: 35, Loss: 0.313224\n",
            "Epoch: 36, Loss: 0.338860\n",
            "Epoch: 37, Loss: 0.275797\n",
            "Epoch: 38, Loss: 0.277019\n",
            "Epoch: 39, Loss: 0.290161\n",
            "Epoch: 40, Loss: 0.240466\n",
            "Epoch: 41, Loss: 0.323922\n",
            "Epoch: 42, Loss: 0.194603\n",
            "Epoch: 43, Loss: 0.161701\n",
            "Epoch: 44, Loss: 0.203112\n",
            "Epoch: 45, Loss: 0.401138\n",
            "Epoch: 46, Loss: 0.254037\n",
            "Epoch: 47, Loss: 0.256931\n",
            "Epoch: 48, Loss: 0.401522\n",
            "Epoch: 49, Loss: 0.817770\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for imgs, labels in valid_dataloader:\n",
        "    batch_size = imgs.shape[0]\n",
        "    pred = model(imgs.view(batch_size, -1))\n",
        "    _, predictions = torch.max(pred, dim=1)\n",
        "    total += labels.shape[0]\n",
        "    correct += int((predictions == labels).sum())\n",
        "\n",
        "print(\"Accuracy: %f\", correct / total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8zPCJFBXaF8",
        "outputId": "96e6e39b-47cd-4f52-b9b3-a1c3d6935ea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: %f 0.817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## conv model\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # image => 3*32*32\n",
        "    self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "    self.dropout_1 = nn.Dropout(p=0.4)\n",
        "\n",
        "    # image 16*16*16\n",
        "    self.conv2 = nn.Conv2d(32, 16, kernel_size=3, padding=1)\n",
        "    self.dropout_2 = nn.Dropout(p=0.4)\n",
        "\n",
        "    # image 8*8*8\n",
        "    self.fc1 = nn.Linear(16*8*8, 32)\n",
        "    self.fc2 = nn.Linear(32, 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "    x = self.dropout_1(x)\n",
        "    x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "    x = self.dropout_2(x)\n",
        "    x = x.view(-1, 16*8*8)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "tvjBaDA1YqMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTd6X1H_541V",
        "outputId": "c868a259-9113-4249-a828-e88a2ba71ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (dropout_1): Dropout(p=0.4, inplace=False)\n",
              "  (conv2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (dropout_2): Dropout(p=0.4, inplace=False)\n",
              "  (fc1): Linear(in_features=1024, out_features=32, bias=True)\n",
              "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(n_epochs, model, optimizer, loss_fn, train_loader, val_loader):\n",
        "  model.train()\n",
        "  for epoch in range(n_epochs):\n",
        "    print(f'\\nEpoch {epoch+1}')\n",
        "    train_loss, train_acc = 0.0, 0.0\n",
        "    val_loss, val_acc = 0.0, 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "      outputs = model(images)\n",
        "\n",
        "      _, pred = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, labels)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "      train_loss += loss.item() \n",
        "\n",
        "      train_acc += int((pred == labels).sum()) / len(pred)\n",
        "\n",
        "    # validating \n",
        "    model.eval()\n",
        "    for images, labels in val_loader:\n",
        "      with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "\n",
        "        _, pred = torch.max(outputs, dim=1)\n",
        "\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        val_loss += loss.item()\n",
        "        val_acc += int((pred == labels).sum()) / len(pred)\n",
        "\n",
        "    \n",
        "    train_loss = train_loss / len(train_loader)\n",
        "    train_acc = train_acc / len(train_loader)\n",
        "\n",
        "    val_loss = val_loss / len(val_loader)\n",
        "    val_acc = val_acc / len(val_loader)\n",
        "\n",
        "    print(f\"Training Loss: {train_loss:.3f}   Training Accuracy: {train_acc:.2f}\")\n",
        "    print(f\"Validation Loss: {val_loss:.3f}   Validation Accuracy: {val_acc:.2f}\")"
      ],
      "metadata": {
        "id": "UZ9iYaV-6BHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "akMOX-8x9Oab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loop(\n",
        "    15, \n",
        "    optimizer=optimizer, \n",
        "    model=model, \n",
        "    loss_fn=criterion, \n",
        "    train_loader=train_dataloader,\n",
        "    val_loader = valid_dataloader,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CyTiKEF9Nmx",
        "outputId": "07e186fd-caac-443b-980e-35709e1df5dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "Training Loss: 0.457   Training Accuracy: 0.79\n",
            "Validation Loss: 0.357   Validation Accuracy: 0.84\n",
            "\n",
            "Epoch 2\n",
            "Training Loss: 0.323   Training Accuracy: 0.86\n",
            "Validation Loss: 0.307   Validation Accuracy: 0.87\n",
            "\n",
            "Epoch 3\n",
            "Training Loss: 0.283   Training Accuracy: 0.88\n",
            "Validation Loss: 0.280   Validation Accuracy: 0.88\n",
            "\n",
            "Epoch 4\n",
            "Training Loss: 0.261   Training Accuracy: 0.89\n",
            "Validation Loss: 0.272   Validation Accuracy: 0.89\n",
            "\n",
            "Epoch 5\n",
            "Training Loss: 0.237   Training Accuracy: 0.90\n",
            "Validation Loss: 0.260   Validation Accuracy: 0.90\n",
            "\n",
            "Epoch 6\n",
            "Training Loss: 0.216   Training Accuracy: 0.91\n",
            "Validation Loss: 0.267   Validation Accuracy: 0.89\n",
            "\n",
            "Epoch 7\n",
            "Training Loss: 0.201   Training Accuracy: 0.92\n",
            "Validation Loss: 0.256   Validation Accuracy: 0.90\n",
            "\n",
            "Epoch 8\n",
            "Training Loss: 0.180   Training Accuracy: 0.93\n",
            "Validation Loss: 0.271   Validation Accuracy: 0.90\n",
            "\n",
            "Epoch 9\n",
            "Training Loss: 0.160   Training Accuracy: 0.93\n",
            "Validation Loss: 0.239   Validation Accuracy: 0.90\n",
            "\n",
            "Epoch 10\n",
            "Training Loss: 0.148   Training Accuracy: 0.94\n",
            "Validation Loss: 0.273   Validation Accuracy: 0.91\n",
            "\n",
            "Epoch 11\n",
            "Training Loss: 0.133   Training Accuracy: 0.95\n",
            "Validation Loss: 0.265   Validation Accuracy: 0.90\n",
            "\n",
            "Epoch 12\n",
            "Training Loss: 0.112   Training Accuracy: 0.95\n",
            "Validation Loss: 0.279   Validation Accuracy: 0.90\n",
            "\n",
            "Epoch 13\n",
            "Training Loss: 0.097   Training Accuracy: 0.96\n",
            "Validation Loss: 0.294   Validation Accuracy: 0.91\n",
            "\n",
            "Epoch 14\n",
            "Training Loss: 0.084   Training Accuracy: 0.97\n",
            "Validation Loss: 0.352   Validation Accuracy: 0.90\n",
            "\n",
            "Epoch 15\n",
            "Training Loss: 0.069   Training Accuracy: 0.97\n",
            "Validation Loss: 0.369   Validation Accuracy: 0.90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rQQEni8C-3h4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
# -*- coding: utf-8 -*-
"""NLP_Helper.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qQRWgVwwkFA8Y0syvA8NtInMjwHxqKO0
"""

import string
import re

import pandas as pd
import numpy as np

import nltk
from nltk.corpus import stopwords
from nltk.tokenize import RegexpTokenizer
from nltk.stem import WordNetLemmatizer
from nltk.stem.porter import PorterStemmer
from nltk.stem import PorterStemmer
from nltk.tokenize import TweetTokenizer
from bs4 import BeautifulSoup

nltk.download('stopwords')

# function to remove htm if text contains any html words
def remove_html(text):
    soup = BeautifulSoup(text, 'lxml')
    html_free = soup.get_text()
    return html_free

# Remove punctuation
def remove_punctuation(text):
  punc = '''!()-[]{};:'"\,<>./?@#$%^&*_~'''
  no_punct = ''.join([c for c in text if c not in punc])
  return no_punct

# lower case words 
def lowercase_text(text):
  """
  tokenizer = RegexpTokenizer(r'\w+') --> split in words

  ('\s+', gaps=True) --> grabs everything except spaces as token

  """
  tokenizer = RegexpTokenizer(r'\w+')
  text = tokenizer.tokenize(text.lower())
  return text

# Removing Stop Words
def remove_stopwords(text):
  """
  text --> List of words

  removes all stoep wors form words list
  """
  words = [w for w in text if w not in stopwords.words('english')]
  return words

# Stemming & Lemmatizing
def word_lemmatizer(text):
  """

  Lemmatizing :- maps common words into one base
  lemmatizer --> WordNetLemmatizer()

  """
  lemmatizer = WordNetLemmatizer()
  lem_text = [lemmatizer.lemmatize(i) for i in text]
  return lem_text

def word_stemmer(text):
  """
  Stemming :- It cuts off prefixes and/or endings of words based on common ones.
  stemmer = PorterStemmer()

  """
  stemmer = PorterStemmer()
  stem_text = ' '.join([stemmer.stem(i) for i in text])
  return stem_text

# An complete preprocessing function for tweets
def process_tweet(tweet):
    """Process tweet function.
    Input:
        tweet: a string containing a tweet
    Output:
        tweets_clean: a list of words containing the processed tweet

    """
    stemmer = PorterStemmer()
    stopwords_english = stopwords.words('english')
    # remove stock market tickers like $GE
    tweet = re.sub(r'\$\w*', '', tweet)
    # remove old style retweet text "RT"
    tweet = re.sub(r'^RT[\s]+', '', tweet)
    # remove hyperlinks
    tweet = re.sub(r'https?:\/\/.*[\r\n]*', '', tweet)
    # remove hashtags
    # only removing the hash # sign from the word
    tweet = re.sub(r'#', '', tweet)
    # tokenize tweets
    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,
                               reduce_len=True)
    tweet_tokens = tokenizer.tokenize(tweet)

    tweets_clean = []
    for word in tweet_tokens:
        if (word not in stopwords_english and  # remove stopwords
                word not in string.punctuation):  # remove punctuation
            # tweets_clean.append(word)
            stem_word = stemmer.stem(word)  # stemming word
            tweets_clean.append(stem_word)

    return tweets_clean

# Function to build frequency
def build_freqs(tweets, ys):
    """Build frequencies.
    Input:
        tweets: a list of tweets
        ys: an m x 1 array with the sentiment label of each tweet
            (either 0 or 1)
    Output:
        freqs: a dictionary mapping each (word, sentiment) pair to its
        frequency
    """
    # Convert np array to list since zip needs an iterable.
    # The squeeze is necessary or the list ends up with one element.
    # Also note that this is just a NOP if ys is already a list.
    yslist = np.squeeze(ys).tolist()

    # Start with an empty dictionary and populate it by looping over all tweets
    # and over all processed words in each tweet.
    freqs = {}
    for y, tweet in zip(yslist, tweets):
        for word in process_tweet(tweet):
            pair = (word, y)
            if pair in freqs:
                freqs[pair] += 1
            else:
                freqs[pair] = 1

    return freqs

def lookup(freqs, word, label):
    '''
    Input:
        freqs: a dictionary with the frequency of each pair (or tuple)
        word: the word to look up
        label: the label corresponding to the word
    Output:
        n: the number of times the word with its corresponding label appears.
    '''
    n = 0  # freqs.get((word, label), 0)

    pair = (word, label)
    if (pair in freqs):
        n = freqs[pair]

    return n